{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raid6/home/yokoyama/har-for-or\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid6/home/yokoyama/har-for-or/.venv/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n"
     ]
    }
   ],
   "source": [
    "%cd /raid6/home/yokoyama/har-for-or/\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\".\")\n",
    "from src.utils import yaml_handler, vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_num = 5\n",
    "# video_num = 11\n",
    "\n",
    "# # load preds\n",
    "# data_root = f\"../datasets/dataset{dataset_num:02d}/train/{video_num:02d}\"\n",
    "# paths = glob(os.path.join(data_root, f\"pred_{model_type}\", \"*\"))\n",
    "# results = []\n",
    "# for path in paths:\n",
    "#     with open(path, \"rb\") as f:\n",
    "#         results.append(pickle.load(f))\n",
    "\n",
    "# # count labels\n",
    "# labels = {}\n",
    "# for result in results:\n",
    "#     key = result[\"key\"]\n",
    "#     video_num, n_frame, _id = key.split(\"_\")\n",
    "#     key = f\"{video_num}_{_id}\"\n",
    "\n",
    "#     if key not in labels:\n",
    "#         labels[key] = []\n",
    "#     labels[key].append(result[\"label\"])\n",
    "\n",
    "# # get most frequent labels\n",
    "# data = []\n",
    "# for key, val in labels.items():\n",
    "#     unique, counts = np.unique(val, return_counts=True)\n",
    "#     maxidx = np.argmax(counts)\n",
    "#     label = unique[maxidx].item()\n",
    "#     data.append([key, label])\n",
    "\n",
    "# # save\n",
    "# path = f\"../datasets/dataset{dataset_num:02d}/annotation/role_train_{video_num}.txt\"\n",
    "# np.savetxt(path, data, fmt=\"%s\", delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "model_type = \"sqvae\"\n",
    "dataset_num = 5\n",
    "if dataset_num == 3:\n",
    "    v = 0\n",
    "elif dataset_num == 4:\n",
    "    v = 1\n",
    "elif dataset_num == 5:\n",
    "    v = 2\n",
    "checkpoint_dir = f\"models/individual/{model_type}/version_{v}\"\n",
    "\n",
    "\n",
    "# load classes\n",
    "path = f\"../datasets/dataset{dataset_num:02d}/annotation/classes.txt\"\n",
    "classes = np.loadtxt(path, str, usecols=0, delimiter=\",\")\n",
    "classes = [c.title() for c in classes]\n",
    "\n",
    "# load annotation\n",
    "path = glob(f\"../datasets/dataset{dataset_num:02d}/annotation/*test*.txt\")[0]\n",
    "video_num = int(os.path.basename(path).split(\".\")[0].split(\"_\")[2])\n",
    "annotations = np.loadtxt(path, str, skiprows=1, delimiter=\" \")\n",
    "\n",
    "# load config\n",
    "config = yaml_handler.load(f\"{checkpoint_dir}/individual-{model_type}.yaml\")\n",
    "seq_len = config.seq_len\n",
    "stride = config.stride\n",
    "if config.mask_leg:\n",
    "    n_pts = 13 + 2\n",
    "else:\n",
    "    n_pts = 17 + 2\n",
    "\n",
    "# load preds\n",
    "data_root = f\"../datasets/dataset{dataset_num:02d}/test/{video_num:02d}\"\n",
    "paths = glob(os.path.join(data_root, f\"pred_{model_type}\", \"*\"))\n",
    "results = []\n",
    "for path in paths:\n",
    "    with open(path, \"rb\") as f:\n",
    "        results.append(pickle.load(f))\n",
    "\n",
    "img_dir = f\"../datasets/dataset{dataset_num:02d}/images\"\n",
    "os.makedirs(img_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirs = glob(f\"../datasets/dataset{dataset_num:02d}/train/*/\") + glob(\n",
    "    f\"../datasets/dataset{dataset_num:02d}/test/*/\"\n",
    ")\n",
    "\n",
    "# sort by video_num\n",
    "data_dirs = sorted(data_dirs, key=lambda x: int(os.path.basename(os.path.dirname(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:34<00:00,  2.29s/it]\n"
     ]
    }
   ],
   "source": [
    "for data_dir in tqdm(data_dirs):\n",
    "    video_num = os.path.basename(os.path.dirname(data_dir))\n",
    "\n",
    "    # load preds\n",
    "    paths = glob(os.path.join(data_dir, f\"pred_{model_type}\", \"*\"))\n",
    "    results = []\n",
    "    for path in paths:\n",
    "        with open(path, \"rb\") as f:\n",
    "            results.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"clustering label\")\n",
    "# X = np.array(latent_features[\"ze\"]).reshape(-1, config.latent_ndim * n_pts * 2)\n",
    "# labels = np.array(latent_features[\"label\"])\n",
    "# vis.plot_tsne(X, labels, 10, None, True, cmap=\"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
